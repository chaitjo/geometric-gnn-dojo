{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propogating geometric information: $k$-chains\n",
    "\n",
    "*Background:*\n",
    "In geometric GNNs, **geometric information**, such as the relative orientation of local neighbourhoods, is propagated via summing features from multiple layers in fixed dimensional spaces. \n",
    "The ideal architecture can be run for any number of layers to perfectly propagate geometric information without loss of information.\n",
    "In practice, stacking geometric GNN layers may lead to distortion or **loss of information from distant nodes**.\n",
    "\n",
    "*Experiment:*\n",
    "To study the practical implications of depth in propagating geometric information beyond local neighbourhoods, we consider **$k$-chain geometric graphs** which generalise the examples from [SchÃ¼tt et al., 2021](https://arxiv.org/abs/2102.03150). \n",
    "Each pair of $k$-chains consists of $k+2$ nodes with $k$ nodes arranged in a line and differentiated by the orientation of the $2$ end points.\n",
    "Thus, $k$-chain graphs are $(\\lfloor \\frac{k}{2} \\rfloor + 1)$-hop distinguishable, and $(\\lfloor \\frac{k}{2} \\rfloor + 1)$ geometric GNN iterations should be theoretically sufficient to distinguish them.\n",
    "In this notebook, we train equivariant and invariant geometric GNNs with an increasing number of layers to distinguish $k$-chains.\n",
    "\n",
    "![k-chains](fig/kchains.png)\n",
    "\n",
    "*Results:*\n",
    "- Despite the supposed simplicity of the task, especially for small chain lengths, we find that popular equivariant GNNs such as E-GNN and TFN may require **more iterations** than theoretically sufficient.\n",
    "- Notably, as the length of the chain gets larger than $k=4$, all equivariant GNNs tended to lose performance and required more than $(\\lfloor \\frac{k}{2} \\rfloor + 1)$ iterations to solve the task.\n",
    "- Invariant GNNs are **unable** to distinguish $k$-chains.\n",
    "\n",
    "These results point to preliminary evidence of the **oversquashing** phenomenon when geometric information is propagated across multiple layers using fixed dimensional feature spaces.\n",
    "These issues are most evident for E-GNN, which uses a single vector feature to aggregate and propagate geometric information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_undirected\n",
    "import e3nn\n",
    "from functools import partial\n",
    "\n",
    "print(\"PyTorch version {}\".format(torch.__version__))\n",
    "print(\"PyG version {}\".format(torch_geometric.__version__))\n",
    "print(\"e3nn version {}\".format(e3nn.__version__))\n",
    "\n",
    "from experiments.utils.plot_utils import plot_3d\n",
    "from experiments.utils.train_utils import run_experiment\n",
    "from models import SchNetModel, DimeNetPPModel, SphereNetModel, EGNNModel, GVPGNNModel, TFNModel, MACEModel\n",
    "\n",
    "# Set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kchains(k):\n",
    "    assert k >= 2\n",
    "    \n",
    "    dataset = []\n",
    "\n",
    "    # Graph 0\n",
    "    atoms = torch.LongTensor( [0] + [0] + [0]*(k-1) + [0] )\n",
    "    edge_index = torch.LongTensor( [ [i for i in range((k+2) - 1)], [i for i in range(1, k+2)] ] )\n",
    "    pos = torch.FloatTensor(\n",
    "        [[-4, -3, 0]] + \n",
    "        [[0, 5*i , 0] for i in range(k)] + \n",
    "        [[4, 5*(k-1) + 3, 0]]\n",
    "    )\n",
    "    center_of_mass = torch.mean(pos, dim=0)\n",
    "    pos = pos - center_of_mass\n",
    "    y = torch.LongTensor([0])  # Label 0\n",
    "    data1 = Data(atoms=atoms, edge_index=edge_index, pos=pos, y=y)\n",
    "    data1.edge_index = to_undirected(data1.edge_index)\n",
    "    dataset.append(data1)\n",
    "    \n",
    "    # Graph 1\n",
    "    atoms = torch.LongTensor( [0] + [0] + [0]*(k-1) + [0] )\n",
    "    edge_index = torch.LongTensor( [ [i for i in range((k+2) - 1)], [i for i in range(1, k+2)] ] )\n",
    "    pos = torch.FloatTensor(\n",
    "        [[4, -3, 0]] + \n",
    "        [[0, 5*i , 0] for i in range(k)] + \n",
    "        [[4, 5*(k-1) + 3, 0]]\n",
    "    )\n",
    "    center_of_mass = torch.mean(pos, dim=0)\n",
    "    pos = pos - center_of_mass\n",
    "    y = torch.LongTensor([1])  # Label 1\n",
    "    data2 = Data(atoms=atoms, edge_index=edge_index, pos=pos, y=y)\n",
    "    data2.edge_index = to_undirected(data2.edge_index)\n",
    "    dataset.append(data2)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "\n",
    "# Create dataset\n",
    "dataset = create_kchains(k=k)\n",
    "for data in dataset:\n",
    "    plot_3d(data, lim=5*k)\n",
    "\n",
    "# Create dataloaders\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(dataset, batch_size=2, shuffle=False)\n",
    "test_loader = DataLoader(dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model\n",
    "model_name = \"gvp\"\n",
    "\n",
    "for num_layers in range(k // 2 , k + 3):\n",
    "\n",
    "    print(f\"\\nNumber of layers: {num_layers}\")\n",
    "    \n",
    "    correlation = 2\n",
    "    model = {\n",
    "        \"schnet\": SchNetModel,\n",
    "        \"dimenet\": DimeNetPPModel,\n",
    "        \"spherenet\": SphereNetModel,\n",
    "        \"egnn\": EGNNModel,\n",
    "        \"gvp\": partial(GVPGNNModel, s_dim=32, v_dim=1),\n",
    "        \"tfn\": TFNModel,\n",
    "        \"mace\": partial(MACEModel, correlation=correlation),\n",
    "    }[model_name](num_layers=num_layers, in_dim=1, out_dim=2)\n",
    "    \n",
    "    best_val_acc, test_acc, train_time = run_experiment(\n",
    "        model, \n",
    "        dataloader,\n",
    "        val_loader, \n",
    "        test_loader,\n",
    "        n_epochs=100,\n",
    "        n_times=10,\n",
    "        device=device,\n",
    "        verbose=False\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94aa676993820a604ac86f7af94f5432e989a749d5dd43e18f9507de2e8c2897"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
